{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa44c477-b86e-4616-a9bc-7a34d8a55584",
   "metadata": {},
   "source": [
    "# Primary analyses of our sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "babb3bf0-a258-4eec-8547-713c3534550e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import qiime2 as q2\n",
    "from qiime2 import Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Define the data directory\n",
    "data_dir = '/home/jovyan/FunGut2/full-pipeline/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b15e1b8-4679-493d-8f1d-737a4e8b6a34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab90f7a-9a8e-4495-a6b6-ecf02e8920f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0989b6a4-852d-4131-9fd3-857f7781c474",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: \u001b[94mqiime sample-classifier classify-samples\u001b[0m [OPTIONS]\n",
      "\n",
      "  Predicts a categorical sample metadata column using a supervised learning\n",
      "  classifier. Splits input data into training and test sets. The training set\n",
      "  is used to train and test the estimator using a stratified k-fold cross-\n",
      "  validation scheme. This includes optional steps for automated feature\n",
      "  extraction and hyperparameter optimization. The test set validates\n",
      "  classification accuracy of the optimized estimator. Outputs classification\n",
      "  results for test set. For more details on the learning algorithm, see\n",
      "  http://scikit-learn.org/stable/supervised_learning.html\n",
      "\n",
      "\u001b[1mInputs\u001b[0m:\n",
      "  \u001b[94m\u001b[4m--i-table\u001b[0m ARTIFACT \u001b[32mFeatureTable[Frequency | RelativeFrequency |\u001b[0m\n",
      "    \u001b[32mPresenceAbsence | Composition]\u001b[0m\n",
      "                          Feature table containing all features that should\n",
      "                          be used for target prediction.            \u001b[35m[required]\u001b[0m\n",
      "\u001b[1mParameters\u001b[0m:\n",
      "  \u001b[94m\u001b[4m--m-metadata-file\u001b[0m METADATA\n",
      "  \u001b[94m\u001b[4m--m-metadata-column\u001b[0m COLUMN  \u001b[32mMetadataColumn[Categorical]\u001b[0m\n",
      "                          Categorical metadata column to use as prediction\n",
      "                          target.                                   \u001b[35m[required]\u001b[0m\n",
      "  \u001b[94m--p-test-size\u001b[0m PROPORTION\n",
      "    \u001b[32mRange(0.0, 1.0)\u001b[0m       Fraction of input samples to exclude from training\n",
      "                          set and use for classifier testing.   \u001b[35m[default: 0.2]\u001b[0m\n",
      "  \u001b[94m--p-step\u001b[0m PROPORTION \u001b[32mRange(0.0, 1.0, inclusive_start=False)\u001b[0m\n",
      "                          If \u001b[4moptimize-feature-selection\u001b[0m is True, step is the\n",
      "                          percentage of features to remove at each iteration.\n",
      "                                                               \u001b[35m[default: 0.05]\u001b[0m\n",
      "  \u001b[94m--p-cv\u001b[0m INTEGER          Number of k-fold cross-validations to perform.\n",
      "    \u001b[32mRange(1, None)\u001b[0m                                                \u001b[35m[default: 5]\u001b[0m\n",
      "  \u001b[94m--p-random-state\u001b[0m INTEGER\n",
      "                          Seed used by random number generator.     \u001b[35m[optional]\u001b[0m\n",
      "  \u001b[94m--p-n-jobs\u001b[0m NTHREADS     Number of jobs to run in parallel.      \u001b[35m[default: 1]\u001b[0m\n",
      "  \u001b[94m--p-n-estimators\u001b[0m INTEGER\n",
      "    \u001b[32mRange(1, None)\u001b[0m        Number of trees to grow for estimation. More trees\n",
      "                          will improve predictive accuracy up to a threshold\n",
      "                          level, but will also increase time and memory\n",
      "                          requirements. This parameter only affects ensemble\n",
      "                          estimators, such as Random Forest, AdaBoost,\n",
      "                          ExtraTrees, and GradientBoosting.     \u001b[35m[default: 100]\u001b[0m\n",
      "  \u001b[94m--p-estimator\u001b[0m TEXT \u001b[32mChoices('RandomForestClassifier',\u001b[0m\n",
      "    \u001b[32m'ExtraTreesClassifier', 'GradientBoostingClassifier',\u001b[0m\n",
      "    \u001b[32m'AdaBoostClassifier[DecisionTree]', 'AdaBoostClassifier[ExtraTrees]',\u001b[0m\n",
      "    \u001b[32m'KNeighborsClassifier', 'LinearSVC', 'SVC')\u001b[0m\n",
      "                          Estimator method to use for sample prediction.\n",
      "                                           \u001b[35m[default: 'RandomForestClassifier']\u001b[0m\n",
      "  \u001b[94m--p-optimize-feature-selection\u001b[0m / \u001b[94m--p-no-optimize-feature-selection\u001b[0m\n",
      "                          Automatically optimize input feature selection\n",
      "                          using recursive feature elimination.\n",
      "                                                              \u001b[35m[default: False]\u001b[0m\n",
      "  \u001b[94m--p-parameter-tuning\u001b[0m / \u001b[94m--p-no-parameter-tuning\u001b[0m\n",
      "                          Automatically tune hyperparameters using random\n",
      "                          grid search.                        \u001b[35m[default: False]\u001b[0m\n",
      "  \u001b[94m--p-palette\u001b[0m TEXT \u001b[32mChoices('YellowOrangeBrown', 'YellowOrangeRed',\u001b[0m\n",
      "    \u001b[32m'OrangeRed', 'PurpleRed', 'RedPurple', 'BluePurple', 'GreenBlue',\u001b[0m\n",
      "    \u001b[32m'PurpleBlue', 'YellowGreen', 'summer', 'copper', 'viridis', 'cividis',\u001b[0m\n",
      "    \u001b[32m'plasma', 'inferno', 'magma', 'sirocco', 'drifting', 'melancholy',\u001b[0m\n",
      "    \u001b[32m'enigma', 'eros', 'spectre', 'ambition', 'mysteriousstains', 'daydream',\u001b[0m\n",
      "    \u001b[32m'solano', 'navarro', 'dandelions', 'deepblue', 'verve', 'greyscale')\u001b[0m\n",
      "                          The color palette to use for plotting.\n",
      "                                                          \u001b[35m[default: 'sirocco']\u001b[0m\n",
      "  \u001b[94m--p-missing-samples\u001b[0m TEXT \u001b[32mChoices('error', 'ignore')\u001b[0m\n",
      "                          How to handle missing samples in metadata. \"error\"\n",
      "                          will fail if missing samples are detected. \"ignore\"\n",
      "                          will cause the feature table and metadata to be\n",
      "                          filtered, so that only samples found in both files\n",
      "                          are retained.                     \u001b[35m[default: 'error']\u001b[0m\n",
      "\u001b[1mOutputs\u001b[0m:\n",
      "  \u001b[94m\u001b[4m--o-sample-estimator\u001b[0m ARTIFACT \u001b[32mSampleEstimator[Classifier]\u001b[0m\n",
      "                          Trained sample estimator.                 \u001b[35m[required]\u001b[0m\n",
      "  \u001b[94m\u001b[4m--o-feature-importance\u001b[0m ARTIFACT \u001b[32mFeatureData[Importance]\u001b[0m\n",
      "                          Importance of each input feature to model accuracy.\n",
      "                                                                    \u001b[35m[required]\u001b[0m\n",
      "  \u001b[94m\u001b[4m--o-predictions\u001b[0m ARTIFACT \u001b[32mSampleData[ClassifierPredictions]\u001b[0m\n",
      "                          Predicted target values for each input sample.\n",
      "                                                                    \u001b[35m[required]\u001b[0m\n",
      "  \u001b[94m\u001b[4m--o-model-summary\u001b[0m VISUALIZATION\n",
      "                          Summarized parameter and (if enabled) feature\n",
      "                          selection information for the trained estimator.\n",
      "                                                                    \u001b[35m[required]\u001b[0m\n",
      "  \u001b[94m\u001b[4m--o-accuracy-results\u001b[0m VISUALIZATION\n",
      "                          Accuracy results visualization.           \u001b[35m[required]\u001b[0m\n",
      "  \u001b[94m\u001b[4m--o-probabilities\u001b[0m ARTIFACT \u001b[32mSampleData[Probabilities]\u001b[0m\n",
      "                          Predicted class probabilities for each input\n",
      "                          sample.                                   \u001b[35m[required]\u001b[0m\n",
      "  \u001b[94m\u001b[4m--o-heatmap\u001b[0m VISUALIZATION\n",
      "                          A heatmap of the top 50 most important features\n",
      "                          from the table.                           \u001b[35m[required]\u001b[0m\n",
      "  \u001b[94m\u001b[4m--o-training-targets\u001b[0m ARTIFACT \u001b[32mSampleData[TrueTargets]\u001b[0m\n",
      "                          Series containing true target values of train\n",
      "                          samples                                   \u001b[35m[required]\u001b[0m\n",
      "  \u001b[94m\u001b[4m--o-test-targets\u001b[0m ARTIFACT \u001b[32mSampleData[TrueTargets]\u001b[0m\n",
      "                          Series containing true target values of test\n",
      "                          samples                                   \u001b[35m[required]\u001b[0m\n",
      "\u001b[1mMiscellaneous\u001b[0m:\n",
      "  \u001b[94m--output-dir\u001b[0m PATH       Output unspecified results to a directory\n",
      "  \u001b[94m--verbose\u001b[0m / \u001b[94m--quiet\u001b[0m     Display verbose output to stdout and/or stderr\n",
      "                          during execution of this action. Or silence output\n",
      "                          if execution is successful (silence is golden).\n",
      "  \u001b[94m--recycle-pool\u001b[0m TEXT     Use a cache pool for pipeline resumption. QIIME 2\n",
      "                          will cache your results in this pool for reuse by\n",
      "                          future invocations. These pool are retained until\n",
      "                          deleted by the user. If not provided, QIIME 2 will\n",
      "                          create a pool which is automatically reused by\n",
      "                          invocations of the same action and removed if the\n",
      "                          action is successful. Note: these pools are local to\n",
      "                          the cache you are using.\n",
      "  \u001b[94m--no-recycle\u001b[0m            Do not recycle results from a previous failed\n",
      "                          pipeline run or save the results from this run for\n",
      "                          future recycling.\n",
      "  \u001b[94m--parallel\u001b[0m              Execute your action in parallel. This flag will use\n",
      "                          your default parallel config.\n",
      "  \u001b[94m--parallel-config\u001b[0m FILE  Execute your action in parallel using a config at\n",
      "                          the indicated path.\n",
      "  \u001b[94m--use-cache\u001b[0m DIRECTORY   Specify the cache to be used for the intermediate\n",
      "                          work of this pipeline. If not provided, the default\n",
      "                          cache under $TMP/qiime2/<uname> will be used.\n",
      "                          IMPORTANT FOR HPC USERS: If you are on an HPC system\n",
      "                          and are using parallel execution it is important to\n",
      "                          set this to a location that is globally accessible\n",
      "                          to all nodes in the cluster.\n",
      "  \u001b[94m--example-data\u001b[0m PATH     Write example data and exit.\n",
      "  \u001b[94m--citations\u001b[0m             Show citations and exit.\n",
      "  \u001b[94m--help\u001b[0m                  Show this message and exit.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!qiime sample-classifier classify-samples --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3134d4-183f-4d1f-ab22-c5b014051d0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c4861bc8-341c-4bca-9bea-1ebdfcbc263f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'machLearning': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! rm -r machLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d7debc8c-3174-4d6b-bf49-9ce934b48fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mPlugin error from sample-classifier:\n",
      "\n",
      "  You have chosen to predict a metadata column that contains one or more values that match only one sample. For proper stratification of data into training and test sets, each class (value) must contain at least two samples. This is a requirement for classification problems, but stratification can be disabled for regression by setting stratify=False. Alternatively, remove all samples that bear a unique class label for your chosen metadata column. Note that disabling stratification can negatively impact predictive accuracy for small data sets.\n",
      "\n",
      "Debug info has been saved to /tmp/qiime2-q2cli-err-hbw9r7rf.log\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!qiime sample-classifier classify-samples \\\n",
    "    --i-table $data_dir/feature_tables_dada/filtered-feature-table.qza \\\n",
    "    --m-metadata-file $data_dir/metadata/fungut_metadata_processed.tsv \\\n",
    "    --m-metadata-column country_sample \\\n",
    "    --p-random-state 42 \\\n",
    "    --p-parameter-tuning \\\n",
    "    --p-estimator RandomForestClassifier \\\n",
    "    --output-dir ./machLearning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "673207f1-1e5b-41c0-a9f6-0e51e8c874cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "machLearning/accuracy_results.qzv does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[235], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mVisualization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./machLearning/accuracy_results.qzv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qiime2/sdk/result.py:75\u001b[0m, in \u001b[0;36mResult.load\u001b[0;34m(cls, filepath)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Check if the data is already in the cache (if the uuid is in\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# cache.data) and load it from the cache if it is. Avoids unzipping the\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# qza again if we already have it.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m cache \u001b[38;5;241m=\u001b[39m get_cache()\n\u001b[0;32m---> 75\u001b[0m peek \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpeek\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m archiver \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39m_load_uuid(peek\u001b[38;5;241m.\u001b[39muuid)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m archiver:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qiime2/sdk/result.py:59\u001b[0m, in \u001b[0;36mResult.peek\u001b[0;34m(cls, filepath)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpeek\u001b[39m(\u001b[38;5;28mcls\u001b[39m, filepath):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ResultMetadata(\u001b[38;5;241m*\u001b[39m\u001b[43marchive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mArchiver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpeek\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qiime2/core/archive/archiver.py:336\u001b[0m, in \u001b[0;36mArchiver.peek\u001b[0;34m(cls, filepath)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpeek\u001b[39m(\u001b[38;5;28mcls\u001b[39m, filepath):\n\u001b[0;32m--> 336\u001b[0m     archive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     Format \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_format_class(archive\u001b[38;5;241m.\u001b[39mversion)\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qiime2/core/archive/archiver.py:315\u001b[0m, in \u001b[0;36mArchiver.get_archive\u001b[0;34m(cls, filepath)\u001b[0m\n\u001b[1;32m    313\u001b[0m filepath \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(filepath)\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filepath\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m filepath)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _ZipArchive\u001b[38;5;241m.\u001b[39mis_archive_type(filepath):\n\u001b[1;32m    318\u001b[0m     archive \u001b[38;5;241m=\u001b[39m _ZipArchive(filepath)\n",
      "\u001b[0;31mValueError\u001b[0m: machLearning/accuracy_results.qzv does not exist."
     ]
    }
   ],
   "source": [
    "Visualization.load('./machLearning/accuracy_results.qzv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73989158-4d97-4069-9f41-06982ad47a6c",
   "metadata": {},
   "source": [
    "# Self made Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "edd7f4a8-ae66-4904-99e3-0a85e099e513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import qiime2 as q2\n",
    "from qiime2 import Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import SparsePCA\n",
    "\n",
    "# Define the data directory\n",
    "data_dir = '/home/jovyan/FunGut2/full-pipeline/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b735be4-5936-48b7-886a-3a5b886f57d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip show seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dff987-59e9-4312-b195-cb141b48b9c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc2eee9-5700-4c4b-9a4b-dc2c898cb657",
   "metadata": {},
   "source": [
    "### export feature table and load as data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dd5433-0e7d-456c-bf07-d945ded5443b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!qiime tools export \\\n",
    "        --input-path $data_dir/feature_tables_dada/filtered-feature-table.qza \\\n",
    "        --output-path $data_dir/feature_tables_dada/exported-feature-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a240acc-2366-4e7a-9c2b-90b4b3a1f2ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ERR5327198</th>\n",
       "      <th>ERR5327199</th>\n",
       "      <th>ERR5327266</th>\n",
       "      <th>ERR5327282</th>\n",
       "      <th>ERR5327284</th>\n",
       "      <th>ERR5327285</th>\n",
       "      <th>ERR5327287</th>\n",
       "      <th>ERR5327288</th>\n",
       "      <th>ERR5327289</th>\n",
       "      <th>ERR5327300</th>\n",
       "      <th>...</th>\n",
       "      <th>ERR5327586</th>\n",
       "      <th>ERR5327587</th>\n",
       "      <th>ERR5327591</th>\n",
       "      <th>ERR5327592</th>\n",
       "      <th>ERR5327596</th>\n",
       "      <th>ERR5327599</th>\n",
       "      <th>ERR5327604</th>\n",
       "      <th>ERR5327605</th>\n",
       "      <th>ERR5327615</th>\n",
       "      <th>ERR5327620</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25bc419d2059b2ae08c91108b86b71e6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5f53f50aea8a5462421d845b18e60151</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192eb2ce554d1b2e5e7c08135413e10b</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5422.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f03e4889f73ea08958135b0757e539dd</th>\n",
       "      <td>8010.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a112f028910db87dfd35a3a916544d74</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  ERR5327198  ERR5327199  ERR5327266  \\\n",
       "25bc419d2059b2ae08c91108b86b71e6           0           0           0   \n",
       "5f53f50aea8a5462421d845b18e60151           0           0           0   \n",
       "192eb2ce554d1b2e5e7c08135413e10b           0           0           0   \n",
       "f03e4889f73ea08958135b0757e539dd      8010.0           0           0   \n",
       "a112f028910db87dfd35a3a916544d74           0           0           0   \n",
       "\n",
       "                                  ERR5327282  ERR5327284  ERR5327285  \\\n",
       "25bc419d2059b2ae08c91108b86b71e6           0           0           0   \n",
       "5f53f50aea8a5462421d845b18e60151           0           0           0   \n",
       "192eb2ce554d1b2e5e7c08135413e10b           0           0           0   \n",
       "f03e4889f73ea08958135b0757e539dd           0           0           0   \n",
       "a112f028910db87dfd35a3a916544d74           0           0           0   \n",
       "\n",
       "                                  ERR5327287  ERR5327288  ERR5327289  \\\n",
       "25bc419d2059b2ae08c91108b86b71e6           0           0           0   \n",
       "5f53f50aea8a5462421d845b18e60151           0           0           0   \n",
       "192eb2ce554d1b2e5e7c08135413e10b           0           0           0   \n",
       "f03e4889f73ea08958135b0757e539dd           0           0           0   \n",
       "a112f028910db87dfd35a3a916544d74           0           0           0   \n",
       "\n",
       "                                  ERR5327300  ...  ERR5327586  ERR5327587  \\\n",
       "25bc419d2059b2ae08c91108b86b71e6           0  ...           0           0   \n",
       "5f53f50aea8a5462421d845b18e60151           0  ...           0           0   \n",
       "192eb2ce554d1b2e5e7c08135413e10b           0  ...           0           0   \n",
       "f03e4889f73ea08958135b0757e539dd        51.0  ...           0           0   \n",
       "a112f028910db87dfd35a3a916544d74           0  ...           0           0   \n",
       "\n",
       "                                  ERR5327591  ERR5327592  ERR5327596  \\\n",
       "25bc419d2059b2ae08c91108b86b71e6           0           0           0   \n",
       "5f53f50aea8a5462421d845b18e60151           0           0           0   \n",
       "192eb2ce554d1b2e5e7c08135413e10b           0      5422.0           0   \n",
       "f03e4889f73ea08958135b0757e539dd           0           0           0   \n",
       "a112f028910db87dfd35a3a916544d74           0           0           0   \n",
       "\n",
       "                                  ERR5327599  ERR5327604  ERR5327605  \\\n",
       "25bc419d2059b2ae08c91108b86b71e6           0           0           0   \n",
       "5f53f50aea8a5462421d845b18e60151           0           0           0   \n",
       "192eb2ce554d1b2e5e7c08135413e10b           0           0           0   \n",
       "f03e4889f73ea08958135b0757e539dd           0           0         9.0   \n",
       "a112f028910db87dfd35a3a916544d74           0           0           0   \n",
       "\n",
       "                                  ERR5327615  ERR5327620  \n",
       "25bc419d2059b2ae08c91108b86b71e6           0           0  \n",
       "5f53f50aea8a5462421d845b18e60151           0           0  \n",
       "192eb2ce554d1b2e5e7c08135413e10b           0           0  \n",
       "f03e4889f73ea08958135b0757e539dd           0           0  \n",
       "a112f028910db87dfd35a3a916544d74           0           0  \n",
       "\n",
       "[5 rows x 146 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from biom import load_table\n",
    "import pandas as pd\n",
    "\n",
    "# Load the .biom file\n",
    "biom_table = load_table(f'{data_dir}/feature_tables_dada/exported-feature-table/feature-table.biom')\n",
    "\n",
    "# Convert the biom table to a pandas DataFrame\n",
    "df = biom_table.to_dataframe()\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada033ec-e89f-4d2a-8340-32a42ab19c07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta = pd.read_csv(f'{data_dir}/metadata/fungut_metadata_processed.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0c55e2-06ea-44af-9b65-abca1e7d7d41",
   "metadata": {},
   "source": [
    "### Build Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b80331c1-dc11-4891-b101-fe1ad4228357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example of loading your feature table (from QIIME 2 export) and metadata\n",
    "X = df.T  # Your feature table (e.g., a pandas DataFrame)\n",
    "y = meta.country_sample  # Your target labels (metadata column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a85dcf28-529c-4234-a505-ad0a282c70a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = y[y != 'Not provided']\n",
    "y.unique()\n",
    "X = X.iloc[y.index]\n",
    "\n",
    "#preprocess data\n",
    "X = np.log1p(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ccd25426-1b51-45ec-8389-5552c4555b65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "#spca = SparsePCA(n_components=100, random_state=42)\n",
    "#X = spca.fit_transform(X)\n",
    "\n",
    "# Encode the target labels\n",
    "#le = LabelEncoder()\n",
    "#y = le.fit_transform(y)  # Converts strings to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "3dd013f3-a52d-4eff-a029-55970047ec18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.407020356604264\n"
     ]
    }
   ],
   "source": [
    "print(X.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e39ba7db-ee02-42ce-9ad1-5a72116e4d4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 1, n_samples = 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[231], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Apply SMOTE to the training set --> create new datapoints of minority group (disease)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m X_train_smote, y_train_smote \u001b[38;5;241m=\u001b[39m \u001b[43msmote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#model = RandomForestClassifier(class_weight='balanced', random_state=42)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#model.fit(X_train, y_train)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(scale_pos_weight\u001b[38;5;241m=\u001b[39mscale_pos_weight, use_label_encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/imblearn/base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/imblearn/base.py:112\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[1;32m    110\u001b[0m )\n\u001b[0;32m--> 112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    116\u001b[0m )\n\u001b[1;32m    118\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/imblearn/over_sampling/_smote/base.py:389\u001b[0m, in \u001b[0;36mSMOTE._fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    386\u001b[0m X_class \u001b[38;5;241m=\u001b[39m _safe_indexing(X, target_class_indices)\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_k_\u001b[38;5;241m.\u001b[39mfit(X_class)\n\u001b[0;32m--> 389\u001b[0m nns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn_k_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    390\u001b[0m X_new, y_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_samples(\n\u001b[1;32m    391\u001b[0m     X_class, y\u001b[38;5;241m.\u001b[39mdtype, class_sample, X_class, nns, n_samples, \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    392\u001b[0m )\n\u001b[1;32m    393\u001b[0m X_resampled\u001b[38;5;241m.\u001b[39mappend(X_new)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/neighbors/_base.py:835\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    834\u001b[0m         inequality_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neighbors <= n_samples_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 835\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    836\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minequality_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    837\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neighbors = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_neighbors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, n_samples_fit = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples_fit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    838\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# include n_samples for common tests\u001b[39;00m\n\u001b[1;32m    839\u001b[0m     )\n\u001b[1;32m    841\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[1;32m    842\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 1, n_samples = 1"
     ]
    }
   ],
   "source": [
    "#scale_pos_weight = (len(y_train) - sum(y_train)) / sum(y_train)\n",
    "\n",
    "# Stratified K-Fold Cross-validation (ensures each fold has the same class distribution)\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y), start=1):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Apply SMOTE to the training set --> create new datapoints of minority group (disease)\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    #model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "    #model.fit(X_train, y_train)\n",
    "\n",
    "    model = xgb.XGBClassifier(scale_pos_weight=scale_pos_weight, use_label_encoder=True, eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    #model = LogisticRegression(solver='lbfgs', class_weight='balanced', random_state=42)\n",
    "    #model.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # Evaluate model\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "    print(f'Ratio: {accuracy_score(y_test, y_pred)/((len(y_test) - sum(y_test))/len(y_test))}')\n",
    "    \n",
    "    # Get class distribution using numpy.unique()\n",
    "    unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
    "    unique_pred, counts_pred = np.unique(y_pred, return_counts=True)\n",
    "    # Print class distributions\n",
    "    print(f\"True class distribution: {dict(zip(unique_test, counts_test))}\")\n",
    "    print(f\"Predicted class distribution: {dict(zip(unique_pred, counts_pred))}\")\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    # Plot the confusion matrix as a heatmap\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=np.unique(y), yticklabels=np.unique(y),\n",
    "               annot_kws={\"size\": 14})  # Increase font size for annotations\n",
    "    plt.title(f'Confusion Matrix for Fold {fold}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d77c82-bfbe-4317-b611-d52cbfa99a4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm = np.array(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beef967a-ccff-4f62-bc17-b650ac8b8858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b175dc-74df-47ec-a765-1f286d0a42d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QIIME 2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
